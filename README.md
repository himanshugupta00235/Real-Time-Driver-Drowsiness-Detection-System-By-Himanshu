üöó Real-Time Driver Drowsiness Detection System
This project is a real-time driver drowsiness detection system that uses computer vision and deep learning to monitor a driver‚Äôs face and detect signs of fatigue such as eye closure, yawning, and head tilt. The goal is to provide timely alerts to prevent road accidents caused by drowsy driving.
Features
‚Ä¢	Real-time face and landmark detection using OpenCV and Dlib.
‚Ä¢	Eye Aspect Ratio (EAR), Mouth Aspect Ratio (MAR), and Head Pose Estimation for accurate drowsiness detection.
‚Ä¢	Multi-indicator fusion approach to minimize false positives.
‚Ä¢	Lightweight and deployable on low-cost hardware such as Raspberry Pi.
‚Ä¢	Provides visual and audio alerts when signs of drowsiness are detected.
Technologies Used
‚Ä¢	Python 3
‚Ä¢	OpenCV ‚Äì for video processing
‚Ä¢	Dlib ‚Äì facial landmark detection
‚Ä¢	NumPy / Pandas ‚Äì data handling
‚Ä¢	Flask / Streamlit (optional) ‚Äì for UI integration
‚Ä¢	TensorFlow/Keras ‚Äì for additional deep learning-based classification
Installation
‚Ä¢	Clone the repository:
   git clone https://github.com/himanshugupta00235/Real-Time-Driver-Drowsiness-Detection-System-By-Himanshu.git
‚Ä¢	cd Real-Time-Driver-Drowsiness-Detection-System-By-Himanshu
‚Ä¢	Create and activate a virtual environment (recommended):
   python3 -m venv venv
   source venv/bin/activate   # Mac/Linux
   venv\Scripts\activate      # Windows
‚Ä¢	Install dependencies:
   pip install -r requirements.txt
Usage
‚Ä¢	Run the application:
   python app.py
‚Ä¢	The webcam will start, and the system will begin detecting drowsiness in real-time.
‚Ä¢	If drowsiness is detected, an alert will be triggered.
Project Workflow
‚Ä¢	Face Detection ‚Äì Haar cascade classifier locates the driver‚Äôs face.
‚Ä¢	Facial Landmark Detection ‚Äì Dlib identifies 68 key facial points.
‚Ä¢	Eye Aspect Ratio (EAR) ‚Äì Calculates how long eyes remain closed.
‚Ä¢	Mouth Aspect Ratio (MAR) ‚Äì Detects yawns.
‚Ä¢	Head Pose Estimation ‚Äì Monitors head tilts/nods.
‚Ä¢	Alert System ‚Äì Warns the driver if drowsiness indicators cross thresholds.
Results
‚Ä¢	Achieved ~94.3% accuracy under various lighting conditions.
‚Ä¢	False positive rate reduced to 5.7% compared to traditional PERCLOS-only systems.
‚Ä¢	Real-time performance at 15 FPS on standard hardware.
Future Improvements
‚Ä¢	Integration of infrared cameras for low-light/night driving.
‚Ä¢	Mobile app integration for driver alerts.
‚Ä¢	Cloud-based analytics for fleet monitoring.
Author
‚Ä¢	üë§ Himanshu Gupta
‚Ä¢	üìß Email: himanshugupta00235@gmail.com
‚Ä¢	üåê GitHub: himanshugupta00235 (https://github.com/himanshugupta00235)
